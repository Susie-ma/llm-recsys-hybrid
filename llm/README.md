# ğŸ”® llm-recsys-hybrid

A hybrid recommendation system that integrates traditional recommender models with the semantic understanding and knowledge of large language models (LLMs), enhanced with explainability via RAG (Retrieval-Augmented Generation) and support for OpenAI GPT interfaces.

---

## ğŸ“Œ Key Features

- **Two-Tower Retriever**: Efficient user-item vector matching for candidate retrieval.
- **LLM-as-Ranker**: Use LLMs (e.g. Sentence Transformers or GPT) to rerank candidates with deep semantic understanding.
- **Prompt Engineering**: Transforms user behavior sequences into natural language prompts that LLMs can interpret.
- **RAG-Based Explanation**: Generates human-readable explanations for recommendations.
- **Knowledge Distillation**: Compress LLM knowledge into lightweight models to reduce inference latency.
- **OpenAI API Support**: Optional integration with GPT-3.5 / GPT-4 for enhanced reasoning and ranking.
- **MovieLens Compatible**: Includes sample MovieLens-style data for quick experiments.

---

## ğŸ“ Project Structure
llm-recsys-hybrid/
â”œâ”€â”€ data/ # Sample user and item data (incl. MovieLens)
â”œâ”€â”€ retriever/ # Two-Tower candidate retriever
â”œâ”€â”€ reranker/ # LLM-as-Ranker (local or OpenAI)
â”œâ”€â”€ prompt_engineering/ # User behavior to prompt converter
â”œâ”€â”€ rag_explainer/ # RAG-based explanation system
â”œâ”€â”€ distillation/ # Knowledge distillation trainer
â”œâ”€â”€ tests/ # Unit tests for key modules
â”œâ”€â”€ config.py # Configs and paths
â”œâ”€â”€ main.py # Entry point
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md

---

## âš™ï¸ Installation

```bash
git clone https://github.com/Susie-ma/llm-recsys-hybrid.git
cd llm-recsys-hybrid
pip install -r requirements.txt
ğŸš€ Quick Start
1. Generate prompt from user behavior
from prompt_engineering.behavior_to_prompt import behavior_to_prompt

behavior = ["clicked iPhone 13", "searched MacBook", "browsed Apple Watch"]
prompt = behavior_to_prompt(behavior)
print(prompt)
2. Use SentenceTransformer-based reranker
from reranker.llm_ranker import LLMRanker

ranker = LLMRanker()
candidates = ["iPhone 15", "MacBook Air", "Samsung S23"]
results = ranker.rank(prompt, candidates)

for item, score in results:
    print(f"{item} - Score: {score}")
3. Use OpenAI GPT-based reranker (optional)
# Set your key before running
# export OPENAI_API_KEY=sk-xxx
from reranker.llm_openai_ranker import gpt_rank

results = gpt_rank(prompt, candidates)
4. Generate explanations using RAG
from rag_explainer.explainer import explain_recommendation

print(explain_recommendation(prompt))
ğŸ”‘ Using OpenAI API
export OPENAI_API_KEY=your_openai_key

ğŸ“Š Sample Data
data/sample_items.csv - Item catalog

data/sample_users.json - User behavior logs

data/movielens_sample.csv - MovieLens-style ratings

You can replace these with real data to test retrieval, reranking, and explanation.
ğŸ›  TODO
 Integrate FAISS/BM25 retrieval

 Add LangChain support for RAG

 Online A/B testing logging module

 End-to-end API service (FastAPI/Flask)

ğŸ“„ License
This project is licensed under the MIT License Â© Susie-ma 2025.


